{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenAI API Walkthrough\n",
    "\n",
    "Content:\n",
    "- Create & import OpenAI API Key\n",
    "- The simplest version\n",
    "- Explaining roles\n",
    "- Explaining temperature\n",
    "- Project: Build your ChatGPT Clone or Build a simple GPT-3.5 powered Chatbot\n",
    "\n",
    "**Braindumps**\n",
    "- \n",
    "\n",
    "Why "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chat_response(prompt):\n",
    "    completion = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "    chat_response = completion.choices[0].message.content\n",
    "    return chat_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did you know that honey never spoils? Archaeologists have found pots of honey in ancient Egyptian tombs that are over 3,000 years old and still perfectly edible!\n"
     ]
    }
   ],
   "source": [
    "print(get_chat_response(\"Tell me a fun fact\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The \"Role\" Parameter\n",
    "\n",
    "<image src=\"./images/Roles.png\" alt=\"Roles in LLMs\" width=\"500\" />\n",
    "\n",
    "We can specify 3 types of roles:\n",
    "1. System - Setting the behavior.\n",
    "2. User - You\n",
    "3. Assistant - Chat Model\n",
    "\n",
    "*Ideas*:\n",
    "- Create 2 functions with different system messages and then pass identical prompts to them to show differences.\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Example with the System role\n",
    "\n",
    "def get_polish_response(prompt):\n",
    "    completion = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a friendy assistant that speaks only Polish\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "    return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oto zabawny fakt: W Polsce jest najwiƒôksza na ≈õwiecie liczba jezior sztucznych! W ca≈Çym kraju jest ponad 9 000 takich jezior, co sprawia, ≈ºe Polska jest prawdziwym rajem dla mi≈Ço≈õnik√≥w wodnych atrakcji i sport√≥w.\n"
     ]
    }
   ],
   "source": [
    "print(get_polish_response(\"Tell me a fun fact\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The \"Temperature\" Parameter\n",
    "\n",
    "<image src=\"./images/Temperature.png\" alt=\"Temperature in LLMs\" width=\"500\" />\n",
    "\n",
    "The temperature sets the tradeoff between predictibility and creativity of the model's responses.\n",
    "\n",
    "The lower the temperature, the more predictable and reasonable response.\n",
    "\n",
    "The higher the tempreture, the more creative the model gets. But it may generate nonsense and it increases hallucinations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Large Language Models, temperature plays a crucial role.\n",
    "\n",
    "Here's the temperature explained so that you never forget its meaning üëá\n",
    "\n",
    "\n",
    "**Low Temperature (A Reasoning Brain)** ü§ì üß†\n",
    "\n",
    "LLMs with low temperatures are mad scientists and engineers who are excellent at their craft.\n",
    "\n",
    "Their responses are well-thought and reliable. \n",
    "\n",
    "But they are deterministic and predictable. So they lack creativity.\n",
    "\n",
    "So use low temperature if:\n",
    "- You want more predictable and rule-based text.\n",
    "- Accuracy, reasoning and reliability are important.\n",
    "- You prefer focused and precise results.\n",
    "- Examples: fact-checking, scientific explanations, summarizing information, coding, translating.\n",
    "\n",
    "**Medium Temperature (A Scientific Artist)** üîé ‚úèÔ∏è\n",
    "\n",
    "LLMs with medium temperatures are creative scientists.\n",
    "\n",
    "They know their craft but they're not afraid to experiment.\n",
    "\n",
    "They are the bridge between pure science and pure art.\n",
    "\n",
    "So use medium temperature if:\n",
    "- You seek a balance between creativity and coherence.\n",
    "- You want a mix of familiar and unexpected ideas.\n",
    "- You value diverse and imaginative outputs.\n",
    "- Examples: creative writing, generating alternative solutions.\n",
    "\n",
    "**High Temperature (An Innovative Visionary)** üé® üñåÔ∏è\n",
    "\n",
    "LLMs with high temperatures are romantic dreamers.\n",
    "\n",
    "They are extremely creative but tend to say nonsensical things.\n",
    "\n",
    "They are not afraid to be wrong (and often are wrong).\n",
    "\n",
    "But some of their ideas are possible and lead to groundbreaking discoveries.\n",
    "\n",
    "So use high temperature if:\n",
    "- You want to \"think out of the box\".\n",
    "- You desire wild and unpredictable text.\n",
    "- Unconventional and imaginative ideas are welcome.\n",
    "- You're open to nonsensical or experimental results.\n",
    "- Examples: brainstorming, generating abstract art, exploring new concepts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictible_response(prompt):\n",
    "    completion = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        temperature=0, # set the temperature\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "    chat_response = completion.choices[0].message.content\n",
    "    return chat_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A fun fact is that honey never spoils. Archaeologists have found pots of honey in ancient Egyptian tombs that are over 3,000 years old and still perfectly edible!\n"
     ]
    }
   ],
   "source": [
    "# always the same\n",
    "print(get_predictible_response(\"Tell me a fun fact\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A fun fact is that humans aren't the only living organisms that can speak or communicate. Parrots, for example, are known for their ability to mimic and even learn human speech.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(get_chat_response(\"Tell me a fun fact\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Useful Resources:\n",
    "\n",
    "1. [OpenAI API Reference](/home/kris/dev/llmzoomcamp/Mod1-openai-api.ipynb)\n",
    "2. [OpenAI Playgound](https://platform.openai.com/playground/)\n",
    "3. [ChatGPT Prompt Engineering for Developers](https://learn.deeplearning.ai/chatgpt-prompt-eng/) It's the source of most images used in the notebook.\n",
    "4. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
